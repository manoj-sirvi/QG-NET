# -*- coding: utf-8 -*-
"""bert.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yVMzDlAm9XmsBnm81k3yrXTghSzFEI9M
"""

import torchtext 
from torchtext.legacy import data
import torch 
import torch.nn as nn 
import torch.nn.functional as F
import pandas as pd 
import numpy as np 
import tqdm
from transformers import BertModel, BertLMHeadModel, BertConfig, BertTokenizerFast
from copy import deepcopy 

#root = 'drive/MyDrive/adv_nlp_project'
root = '.'
device = torch.device('cuda')

def get_src_and_feat(line):
  token_level_split = [tok.split('ï¿¨') for tok in line.split()]
  sent = " ".join([i[0] for i in token_level_split])
  features = [[],[],[],[]]
  for token in token_level_split:
    for i, feature in enumerate(token[1:]):
      features[i].append(feature)
  return sent, features

splits_dict = {}
for splt in ['train','dev','test']:
  source = open(f'{root}/data/{splt}/squad.corenlp.filtered.contents.1sent.txt', 'r').readlines()
  target = open(f'{root}/data/{splt}/squad.corenlp.filtered.questions.txt', 'r').readlines()

  result_dict = {
      'src':[],
      'feat_0':[],
      'feat_1':[],
      'feat_2':[],
      'feat_3':[],
      'trg':[]
  }

  for src, trg in zip(source, target):
    sent, features = get_src_and_feat(src.rstrip())
    result_dict['src'].append(sent)
    result_dict['trg'].append(trg.rstrip())
    for i, feat in enumerate(features):
      result_dict[f'feat_{i}'].append(" ".join(feat))

  splits_dict[splt] = result_dict

train_src = splits_dict['train']['src']
#train_feat_0 = splits_dict['train']['feat_0'][:100]
#train_feat_1 = splits_dict['train']['feat_1'][:100]
#train_feat_2 = splits_dict['train']['feat_2'][:100]
#train_feat_3 = splits_dict['train']['feat_3'][:100]
train_trg = splits_dict['train']['trg']

val_src = splits_dict['dev']['src']
#val_feat_0 = splits_dict['dev']['feat_0'][:100]
#val_feat_1 = splits_dict['dev']['feat_1'][:100]
#val_feat_2 = splits_dict['dev']['feat_2'][:100]
#val_feat_3 = splits_dict['dev']['feat_3'][:100]
val_trg = splits_dict['dev']['trg']

tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

train_src_encodings = tokenizer(train_src, padding=True, truncation=True, max_length=128)
val_src_encodings = tokenizer(val_src, padding=True, truncation=True, max_length=128)

train_trg_encodings = tokenizer(train_trg, padding='max_length', truncation=True, max_length=60)
val_trg_encodings = tokenizer(val_trg, padding='max_length', truncation=True, max_length=60)

class QADataset(torch.utils.data.Dataset):
    def __init__(self, src, trg):
        self.src = src
        self.trg = trg 

    def __getitem__(self, idx):
        src_items = {key: torch.tensor(val[idx]) for key, val in self.src.items()}
        trg_items = {key: torch.tensor(val[idx]) for key, val in self.trg.items()}
        
        return {'src':src_items, 'trg':trg_items}

    def __len__(self):
        return len(self.trg['input_ids'])

train_dataset = QADataset(train_src_encodings, train_trg_encodings)
val_dataset = QADataset(val_src_encodings, val_trg_encodings)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True)

class BertDecoder(nn.Module):
  def __init__(self, lm_model, dropout = 0.3):
    super(BertDecoder,self).__init__()
    self.decoder = lm_model
    self.dropout = nn.Dropout(dropout)

     # Attention 
    self.W_h = nn.Parameter(torch.randn((768, 768)))
    self.W_s = nn.Parameter(torch.randn((768, 768)))
    self.v = nn.Parameter(torch.randn((768, 1)))
    self.b_attn = nn.Parameter(torch.randn((1, 768)))

    # Pointer
    self.V = nn.Linear(768*2, 30522)
    self.W_z = nn.Linear(768, 1)

  def forward(self, input_id, input_mask, encoder_outputs, encoder_mask, encoder_word_idx):
    decoder_outputs = self.decoder(input_ids = input_id, attention_mask = input_mask, encoder_hidden_states = encoder_outputs, encoder_attention_mask = encoder_mask)

    decoder_outputs = decoder_outputs.hidden_states[-1].permute(1, 0, 2)
    encoder_outputs = encoder_outputs.permute(1, 0, 2)

    # Attention 
    x1 = encoder_outputs.matmul(self.W_h)
    x2 = decoder_outputs.expand(encoder_outputs.size(0), -1, -1).matmul(self.W_s)
    bias = self.b_attn.unsqueeze(0).repeat(encoder_outputs.size(0), 1, 1)
    res = torch.tanh(x1 + x2 + bias).matmul(self.v).squeeze(2)
    attn = F.softmax(res, 0).transpose(0, 1)

    # Pointer 
    encoder_outputs = encoder_outputs.transpose(0, 1)
    context = attn.unsqueeze(1).bmm(encoder_outputs).squeeze(1)
    global_state = torch.cat((decoder_outputs.squeeze(0), context), 1)
    #p_vocab =  torch.selu(self.V(global_state))
    e = torch.relu(self.V(global_state))
    p_vocab = torch.softmax(self.V_dash(e), 1)

    p_source = attn 
    p = torch.sigmoid(self.W_z(decoder_outputs))
    p = p.squeeze(0)
    que_vocab_distr = p * p_vocab
    inp_vocab_distr = (1 - p) * p_source

    extended_vocab_distr = que_vocab_distr.scatter_add_(1, encoder_word_idx, inp_vocab_distr)
    
    return extended_vocab_distr, p.squeeze(), attn.transpose(0, 1)

class BertPointerNetwork(nn.Module):
  def __init__(self, encoder, decoder):
    super(BertPointerNetwork, self).__init__()
    self.encoder = encoder 
    self.decoder = decoder 
  
  def forward(self, src, trg = None):
    outputs = []
    src_ids, src_mask = src
    encoder_outputs = self.encoder(src_ids, attention_mask = src_mask)
    encoder_outputs = encoder_outputs.last_hidden_state 

    if(trg != None):
      trg_ids, trg_mask = trg
      trg_len = trg_ids.shape[1]
      next_trg_ids = trg_ids[:, 0].unsqueeze(1)
      next_trg_mask = trg_mask[:, 0].unsqueeze(1)

      for t in range(1, trg_len):
        dist, prob, attn = self.decoder(next_trg_ids, next_trg_mask, encoder_outputs, src_mask, src_ids)
        outputs.append(dist)
        next_trg_ids = trg_ids[:, t].unsqueeze(1)
        next_trg_mask = trg_mask[:, t].unsqueeze(1)

    else:
      batch_size = src_ids.shape[0]
      next_trg_ids = (torch.ones(batch_size, device=device) * 102).long().unsqueeze(1)
      next_trg_masks = torch.ones(batch_size, device=device).long().unsqueeze(1)
      for i in range(1, 60):
        dist, prob, attn = self.decoder(next_trg_ids, next_trg_masks, encoder_outputs, src_mask, src_ids)
        outputs.append(dist)
        next_trg_ids = torch.argmax(dist, 1).long().unsqueeze(1)

    return torch.stack(outputs)

def train_step(model, criterion, optimizer, sample):
    optimizer.zero_grad()

    ids = sample['src']['input_ids'].to(device)
    amask = sample['src']['attention_mask'].to(device)

    tids = sample['trg']['input_ids'].to(device)
    tamask = sample['trg']['attention_mask'].to(device)

    dist = model((ids, amask), (tids, tamask))

    trg = tids[:, 1:].reshape(-1, dist.shape[0])
    dist = dist.view(-1, dist.size(2))
    trg = trg.reshape(-1)

    loss = criterion(dist, trg)
    loss.backward()
    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 5)
    optimizer.step()

    return loss.item(), grad_norm

def eval_step(model, criterion, sample):

    ids = sample['src']['input_ids'].to(device)
    amask = sample['src']['attention_mask'].to(device)

    tids = sample['trg']['input_ids'].to(device)
    tamask = sample['trg']['attention_mask'].to(device)

    dist = model((ids, amask))

    trg = tids[:, 1:].reshape(-1, dist.shape[0])
    dist = dist.view(-1, dist.size(2))
    trg = trg.reshape(-1)

    loss = criterion(dist, trg)

    return loss.item()

def train_model(model, train_iter, val_iter, epochs):
  optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)
  criterion = torch.nn.CrossEntropyLoss(ignore_index = 0)

  best_model_weights = None 
  best_valid_loss = np.inf

  for epoch in range(1, epochs+1):
    epoch_train_loss = 0
    epoch_valid_loss = 0

    model.train()
    with(tqdm.tqdm(train_iter, unit="batch")) as tepoch:
      for batch in tepoch:
        tepoch.set_description(f"Epoch {epoch}")
        loss, _ = train_step(model, criterion, optimizer, batch)
        epoch_train_loss += loss
        tepoch.set_postfix(loss=loss)  
    epoch_train_loss = epoch_train_loss/len(train_iter)

    model.eval()
    with(tqdm.tqdm(val_iter, unit="batch")) as tepoch:
      for batch in tepoch:
        tepoch.set_description(f"Epoch {epoch}")
        loss = eval_step(model, criterion, batch)
        epoch_valid_loss += loss
        tepoch.set_postfix(loss=loss)  
    epoch_valid_loss = epoch_valid_loss/len(val_iter)

    if(epoch_train_loss < best_valid_loss):
     best_valid_loss = epoch_valid_loss 
     best_model_weights = deepcopy(model.module.state_dict())

    print(f'\n Epoch {epoch} ; Train loss: {epoch_train_loss}; Valid. loss: \n')

    if(epoch%5 == 0):
      save_dict = {
          'epoch': epoch,
          'model_state_dict': model.module.state_dict(),
          'optimizer_state_dict': optimizer.state_dict(),
      }
      torch.save(save_dict, f'./checkpoints/model_{epoch}.pt')

  return best_model_weights

encoder = BertModel.from_pretrained('bert-base-uncased')

config = BertConfig.from_pretrained("bert-base-uncased")
config.is_decoder = True
config.add_cross_attention=True
config.output_hidden_states=True
lm_model = BertLMHeadModel.from_pretrained('bert-base-uncased', config=config)

decoder = BertDecoder(lm_model)

model = BertPointerNetwork(encoder, decoder)
model = nn.DataParallel(model)
model.to(device)

best_weights = train_model(model, train_loader, val_loader, 3)
torch.save(best_weights, './best_model.pt')

